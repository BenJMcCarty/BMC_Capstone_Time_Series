{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7aafa147-1414-4a3c-8884-17af1fed40f3",
   "metadata": {},
   "source": [
    "# Pre-Pre-Processing\n",
    "\n",
    "Before I start performing any EDA or modeling, I will pre-emptively split my data to have a separate training set of data.\n",
    "\n",
    "Since the data consists of temporal data (hotel reservations across multiple years), I will split the data into two groups based on two datetime features: Booking Date and the Arrival date.\n",
    "\n",
    "---\n",
    "\n",
    "# Consulting ChatGPT\n",
    "\n",
    "I asked ChatGPT to help me decide if one feature would be better than the other. It's responses are as follows:\n",
    "\n",
    "## Booking Date\n",
    "\n",
    "### Pros:\n",
    "> * *Forecasting Lead Time:* Splitting by booking date allows you to model the lead time between booking and arrival, which is valuable for forecasting future demand well in advance.\n",
    "> * *Real-world Scenario Modeling:* This approach mirrors real-world scenarios more closely, where predictions are made as bookings occur, regardless of the future arrival date.\n",
    "> * *Dynamic Pricing and Revenue Management:* Particularly useful for applications in dynamic pricing and revenue management, where understanding booking patterns ahead of time can inform strategic decisions.\n",
    "\n",
    "### Cons:\n",
    "> * *Increased Complexity:* The time gap between booking and arrival dates introduces additional complexity, as you need to account for changes over time that could affect the stay (e.g., cancellations, modifications).\n",
    "\n",
    "\n",
    "\n",
    "## Arrival Date\n",
    "\n",
    "### Pros:\n",
    "> * *Cleaner Data Relationships:* Utilizing the arrival date might result in cleaner, more straightforward modeling, as it directly ties the prediction to the period of service or product consumption.\n",
    "> * *Seasonality and Trend Analysis:* Easier to model seasonal trends and effects, as the arrival date directly corresponds to the period being analyzed.\n",
    "> * *Accuracy in Performance Metrics:* Predictions based on arrival date can be more closely aligned with actual occupancy and revenue, potentially improving model accuracy in terms of performance metrics.\n",
    "\n",
    "### Cons:\n",
    "\n",
    "> * *Reduced Forecasting Horizon:* The model may be less effective at predicting bookings well in advance since it's oriented around the arrival date. This could limit its usefulness for long-term planning.\n",
    "> * *Possible Lag in Actionable Insights:* May not provide as much lead time for implementing strategies based on the predictions, such as staffing or promotional offers, since the focus is on the period closer to the actual stay.\n",
    "\n",
    "---\n",
    "\n",
    "# Consultation Conclusions\n",
    "\n",
    "After considering ChatGPT's suggestions and insights, I will take a more greedy approach and create separate datasets for both the booking and arrival dates. This will give me more flexibility when modeling as I will have different time perspectives to utilize for different purposes (e.g., future forecasting vs. analyzing actualized performance).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b1760a-454d-4b07-b3fc-7249f95e3795",
   "metadata": {},
   "source": [
    "# Date Preparation\n",
    "\n",
    "Before I can split the datasets, I need to perform some slight feature engineering. The source datasets do not have an exact datetime feature for the arrival date, only for the booking date. I will use the separate Year, Month, and Day of Month features to create an `Arrival_Date` feature, then use this feature for splitting my data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c15bd256-e7bb-4caa-9d37-ad1707026556",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-22T20:18:55.671337Z",
     "iopub.status.busy": "2024-03-22T20:18:55.670337Z",
     "iopub.status.idle": "2024-03-22T20:18:58.254834Z",
     "shell.execute_reply": "2024-03-22T20:18:58.254834Z",
     "shell.execute_reply.started": "2024-03-22T20:18:55.671337Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb76b4bf-c5a0-4b83-a131-aaacaafb1d63",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-22T20:19:42.371432Z",
     "iopub.status.busy": "2024-03-22T20:19:42.371432Z",
     "iopub.status.idle": "2024-03-22T20:19:42.599378Z",
     "shell.execute_reply": "2024-03-22T20:19:42.598378Z",
     "shell.execute_reply.started": "2024-03-22T20:19:42.371432Z"
    }
   },
   "outputs": [],
   "source": [
    "## Sharing 'df_data' to reuse code from a prior notebook\n",
    "path1 = './data/H1.parquet'\n",
    "df_data = pd.read_parquet(path1)\n",
    "\n",
    "# ## Sharing 'df_data' to reuse code from a prior notebook\n",
    "# path2 = './data/H2.parquet'\n",
    "# df_data = pd.read_parquet(path2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17868e04-8a42-4b50-99c9-b5bdd597c3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Convert Arrival columns to strings\n",
    "\n",
    "arrival_date_cols = ['ArrivalDateYear', 'ArrivalDateMonth', 'ArrivalDateDayOfMonth']\n",
    "\n",
    "arrival_date_cols_str = df_data[arrival_date_cols].astype(str)\n",
    "arrival_date_cols_str.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ab1dcc3d-72d8-43cf-9748-1964b30a759d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-22T20:59:34.406375Z",
     "iopub.status.busy": "2024-03-22T20:59:34.405374Z",
     "iopub.status.idle": "2024-03-22T20:59:35.367374Z",
     "shell.execute_reply": "2024-03-22T20:59:35.366375Z",
     "shell.execute_reply.started": "2024-03-22T20:59:34.406375Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted C:\\Users\\Ben\\Downloads\\H1.csv to C:\\Users\\Ben\\Downloads\\H1.parquet with brotli compression.\n",
      "Converted C:\\Users\\Ben\\Downloads\\H2.csv to C:\\Users\\Ben\\Downloads\\H2.parquet with brotli compression.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define file paths\n",
    "csv_file_paths = ['C:\\\\Users\\\\Ben\\\\Downloads\\\\H1.csv', 'C:\\\\Users\\\\Ben\\\\Downloads\\\\H2.csv']\n",
    "parquet_file_paths = ['C:\\\\Users\\\\Ben\\\\Downloads\\\\H1.parquet', 'C:\\\\Users\\\\Ben\\\\Downloads\\\\H2.parquet']\n",
    "\n",
    "# Convert each CSV to Parquet with brotli compression\n",
    "for csv_path, parquet_path in zip(csv_file_paths, parquet_file_paths):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    df.to_parquet(parquet_path, engine='pyarrow', compression='brotli')\n",
    "    print(f'Converted {csv_path} to {parquet_path} with brotli compression.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1047771-523d-41fa-914c-5c56bb13876c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dojo-env)",
   "language": "python",
   "name": "dojo-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

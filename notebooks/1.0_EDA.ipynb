{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA and Data Wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Revisiting the Reservations\n",
    "\n",
    "---\n",
    "\n",
    "Originally, I used this notebook to perform EDA with the intention of using the dataset only for classifying whether a reservation would cancel.\n",
    "\n",
    "Now, as part of my efforts to revisit and revamp this overall repository and workflow, I am adapting it for broader uses, such as regression modeling and time series forecasting.\n",
    "\n",
    "The end goal is to have a comprehensive overview of the data and to be flexible enough to handle different workflows.\n",
    "\n",
    "**Warning: Work-in-Progress**\n",
    "\n",
    "As this is a revamp of the original workbook, some of the code and comments may be outdated. I intend to update and clarify all steps in time, but there may be some parts that are out of place while I clean things up.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Of Demand and Cancellations**\n",
    "\n",
    "*This was the initial intro to the notebook with a focus on classification modeling.*\n",
    "\n",
    ">**Every aspect of hospitality depends on accurately anticipating business demand**: how many rooms to clean; how many rooms are available to sell; what would be the best rate; and how to bring it all together to make every guest satisfied. \n",
    ">\n",
    "> Proper forecasting is critical to every department and staff member, and to generate our forecasts, **hotel managers need to know how many guests will cancel prior to arrival**. Using data from two European hotels, I developed a model to predict whether a given reservation would cancel based on 30 different reservation details.\n",
    "\n",
    "**In order to develop and train my models, I need to prepare the data in advance.**\n",
    "\n",
    ">In this notebook, I explore the original dataset and its features; condense several features into smaller subsets; engineer new features; and remove unwanted features from the data.\n",
    ">\n",
    "**Once the data is prepared, I will reload the data in a new notebook to create and train my models to determine my predictions of who will stay and who will cancel.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-05T17:32:52.290987Z",
     "start_time": "2022-11-05T17:32:52.154639Z"
    }
   },
   "outputs": [],
   "source": [
    "## Used to re-import custom functions during development\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Enabling access to custom functions in separate directory\n",
    "\n",
    "# Import necessary modules\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Construct the absolute path to the 'src' directory\n",
    "src_path = os.path.abspath(os.path.join('..', 'src'))\n",
    "\n",
    "# Append the path to 'sys.path'\n",
    "if src_path not in sys.path:\n",
    "    sys.path.append(src_path)\n",
    "\n",
    "import db_utils, eda\n",
    "\n",
    "## Data Handling\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "## Visualizations\n",
    "import matplotlib.pyplot as plt\n",
    "from missingno import matrix\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "\n",
    "## Feature Preprocessing\n",
    "from feature_engine.imputation import CategoricalImputer, MeanMedianImputer\n",
    "from feature_engine.encoding import OneHotEncoder, RareLabelEncoder\n",
    "from feature_engine.outliers import OutlierTrimmer\n",
    "\n",
    "from sklearn.ensemble import IsolationForest, HistGradientBoostingRegressor, HistGradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-05T17:32:52.153128Z",
     "start_time": "2022-11-05T17:32:52.139036Z"
    }
   },
   "outputs": [],
   "source": [
    "## Settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.float_format', lambda x: f'{x:,.2f}')\n",
    "pd.set_option('display.max_rows', 50)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Source Data (with UUIDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Path to the DuckDB database file\n",
    "# db_path = '../data/hotel_reservations.duckdb'\n",
    "\n",
    "# ## Select subset of data for review\n",
    "# q = 'SELECT * FROM res_data LIMIT 5'\n",
    "\n",
    "# with db_utils.duckdb_connection(db_path) as conn:\n",
    "#     data = conn.execute(q).df()\n",
    "    \n",
    "# data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backup_data_path = '../data/data_condensed_with_uuid.parquet'\n",
    "\n",
    "data = pd.read_parquet(backup_data_path)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Pre-Engineered Date Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = '../data/engineered_data_dates.parquet'\n",
    "\n",
    "df_dates = pd.read_parquet(filepath)\n",
    "df_dates.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dates.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Condense to Single DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = data.merge(right = df_dates, how = 'left', on = 'UUID')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropping Select Features\n",
    "\n",
    "*Some features were used to engineer new features - particularly arrival details.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_feats = ['UUID','LeadTime', 'ArrivalDateYear', 'ArrivalDateMonth', 'ArrivalDateWeekNumber',\n",
    "              'ArrivalDateDayOfMonth', 'StaysInWeekendNights', 'StaysInWeekNights',\n",
    "              'ReservationStatusDate_x', 'ReservationStatusDate_y', 'ArrivalDate',\n",
    "              'DepartureDate', 'BookingDate']\n",
    "drop_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(columns = drop_feats)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abbreviated EDA\n",
    "\n",
    "---\n",
    "\n",
    "- Original notebook reviewed each feature in depth\n",
    "- Abbreviating review for simplicity.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Stats via Describe Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Numeric Stats\n",
    "data.describe(include = 'number')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "- Outliers present in many features\n",
    "- Outlier detection/removal may be required in preprocessing pipeline for certain model types\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Non-Numeric Stats\n",
    "data.describe(exclude = 'number')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "- High cardinality in Country, Agent, Company (disregard UUID; reservation ID)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_sum = data.isna().sum()\n",
    "nan_sum[nan_sum>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_avg = data.isna().mean()\n",
    "nan_avg[nan_avg>0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "- Two features missing values\n",
    "- Average number of missing values less than 1%\n",
    "- No action taken; will address in model pipeline\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_number = data.select_dtypes(include = 'number').columns\n",
    "data_non_num = data.select_dtypes(exclude = 'number').columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data_number].hist(bins = 20, figsize = (18,21), layout = (-1, 5));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-Numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vc_params = {'normalize':True, 'dropna': False, 'ascending': False}\n",
    "\n",
    "for col in data_non_num:\n",
    "    if data[col].nunique() < 10:\n",
    "        print(data[col].value_counts(**vc_params),'\\n')\n",
    "    else:\n",
    "        print(data[col].value_counts(**vc_params)[:5], '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Rare-Label Encoding for categories <5%. Binary encoding for features w/ low variance.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop ReservationStatus\n",
    "\n",
    "---\n",
    "\n",
    "> `ReservationStatus` is nearly identical to my target feature and would be too strong of a predictor in my models.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[['ReservationStatus', 'IsCanceled']].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-05T17:33:11.076865Z",
     "start_time": "2022-11-05T17:33:10.906251Z"
    }
   },
   "outputs": [],
   "source": [
    "## Dropping \"reservation_status\"\n",
    "data = data.drop(columns = ['ReservationStatus'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-05T17:33:11.231443Z",
     "start_time": "2022-11-05T17:33:11.077795Z"
    }
   },
   "outputs": [],
   "source": [
    "## Confirming 'reservation_status' removal from dataframe\n",
    "'ReservationStatus' not in data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Feature Preprocessing with `Feature-Engine` Package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Outliers (continuous features): [OutlierTrimmer using MAD](https://feature-engine.trainindata.com/en/latest/user_guide/outliers/OutlierTrimmer.html#maximum-absolute-deviation)\n",
    "    * *Test alternative methods - reduces dataset by 50%.*\n",
    "3. Categorical encoding: [DecisionTreeEncoder](https://feature-engine.trainindata.com/en/latest/api_doc/encoding/DecisionTreeEncoder.html#decisiontreeencoder)\n",
    "   * *Only usable with target feature; not ideal for all-purpose preprocessing.*\n",
    "5. Rare labels (categoricals): [RareLabelEncoding](https://feature-engine.trainindata.com/en/latest/api_doc/encoding/RareLabelEncoder.html#rarelabelencoder)\n",
    "   * *Best option for high cardinality features.*\n",
    "7. Datetime-related features: Review [DatetimeFeatures](https://feature-engine.trainindata.com/en/latest/user_guide/datetime/DatetimeFeatures.html#automating-feature-extraction)\n",
    "   * *Possibly useful for revising datetime feature engineering notebook.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-05T17:33:12.110167Z",
     "start_time": "2022-11-05T17:33:11.925435Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.head().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Value Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isna().sum()[data.isna().sum() > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Instantiate imputers for categorical and continuous features\n",
    "\n",
    "cat_imputer = CategoricalImputer(variables=['Country'], imputation_method = 'frequent')\n",
    "data = cat_imputer.fit_transform(data)\n",
    "\n",
    "num_imputer = MeanMedianImputer(imputation_method = 'median', variables = ['Children'])\n",
    "data = num_imputer.fit_transform(data)\n",
    "\n",
    "\n",
    "data.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rare Label Encoding\n",
    "\n",
    "---\n",
    "\n",
    "* Several features with high degree of cardinality\n",
    "* Performing rare label encoding will reduce the cardinality, making one-hot encoding more efficient and effective\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe(include = 'object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rle = RareLabelEncoder(tol=0.05,n_categories=3,replace_with='Rare')\n",
    "\n",
    "data = rle.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.describe(include = 'object')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-Hot Encoding\n",
    "\n",
    "---\n",
    "\n",
    "* Used after rare label encoding, this will convert my categorical features to numeric.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder(drop_last = True)\n",
    "\n",
    "data = ohe.fit_transform(data)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outlier Detection: Isolation Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = IsolationForest(n_estimators=100, contamination='auto', random_state=42)\n",
    "model.fit(data)\n",
    "\n",
    "# Predict anomalies\n",
    "labels = model.predict(data)\n",
    "\n",
    "# # Calculate anomaly scores\n",
    "# scores = model.decision_function(data)\n",
    "\n",
    "# # Example: Inspect the first 5 predictions and scores\n",
    "# for i in range(5):\n",
    "#     print(f\"Data Point {i+1}: Label = {labels[i]}, Score = {scores[i]:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[labels == -1].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test: Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[labels == 1]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'ADR'\n",
    "# target = 'IsCanceled'\n",
    "\n",
    "X = data.drop(columns = [target])\n",
    "y= data[target]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HistGradientBoostingRegressor(random_state = 42)\n",
    "# model = HistGradientBoostingClassifier(random_state = 42)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# y_pred = model.predict(X_test)\n",
    "\n",
    "model.score(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dojo-env)",
   "language": "python",
   "name": "dojo-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "250.775px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

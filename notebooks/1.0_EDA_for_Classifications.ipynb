{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Hotel Cancel Culture** - **EDA Notebook**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Author:** Ben McCarty\n",
    "\n",
    "**Extension of Capstone Project** - Expanding Hotel Reservation dataset analysis and modeling\n",
    "\n",
    "**Contact:** bmccarty505@gmail.com\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Revisiting the Reservations\n",
    "\n",
    "---\n",
    "\n",
    "Originally, I used this notebook to perform EDA with the intention of using the dataset only for classifying whether a reservation would cancel.\n",
    "\n",
    "Now, as part of my efforts to revisit and revamp this overall repository and workflow, I am adapting it for broader uses, such as regression modeling and time series forecasting.\n",
    "\n",
    "The end goal is to have a comprehensive overview of the data and to be flexible enough to handle different workflows.\n",
    "\n",
    "**Warning: Work-in-Progress**\n",
    "\n",
    "As this is a revamp of the original workbook, some of the code and comments may be outdated. I intend to update and clarify all steps in time, but there may be some parts that are out of place while I clean things up.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Of Demand and Cancellations**\n",
    "\n",
    "*This was the initial intro to the notebook with a focus on classification modeling.*\n",
    "\n",
    ">**Every aspect of hospitality depends on accurately anticipating business demand**: how many rooms to clean; how many rooms are available to sell; what would be the best rate; and how to bring it all together to make every guest satisfied. \n",
    ">\n",
    "> Proper forecasting is critical to every department and staff member, and to generate our forecasts, **hotel managers need to know how many guests will cancel prior to arrival**. Using data from two European hotels, I developed a model to predict whether a given reservation would cancel based on 30 different reservation details.\n",
    "\n",
    "**In order to develop and train my models, I need to prepare the data in advance.**\n",
    "\n",
    ">In this notebook, I explore the original dataset and its features; condense several features into smaller subsets; engineer new features; and remove unwanted features from the data.\n",
    ">\n",
    "**Once the data is prepared, I will reload the data in a new notebook to create and train my models to determine my predictions of who will stay and who will cancel.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Import Packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-05T17:32:52.290987Z",
     "start_time": "2022-11-05T17:32:52.154639Z"
    }
   },
   "outputs": [],
   "source": [
    "## Used to re-import custom functions during development\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Enabling access to custom functions in separate directory\n",
    "\n",
    "# Import necessary modules\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Construct the absolute path to the 'src' directory\n",
    "src_path = os.path.abspath(os.path.join('..', 'src'))\n",
    "\n",
    "# Append the path to 'sys.path'\n",
    "if src_path not in sys.path:\n",
    "    sys.path.append(src_path)\n",
    "\n",
    "import db_utils, eda\n",
    "\n",
    "## Data Handling\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "## Visualizations\n",
    "import matplotlib.pyplot as plt\n",
    "from missingno import matrix\n",
    "import plotly.express as px\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-05T17:32:52.153128Z",
     "start_time": "2022-11-05T17:32:52.139036Z"
    }
   },
   "outputs": [],
   "source": [
    "## Settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.float_format', lambda x: f'{x:,.2f}')\n",
    "pd.set_option('display.max_rows', 50)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Source Data (with UUIDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Path to the DuckDB database file\n",
    "# db_path = '../data/hotel_reservations.duckdb'\n",
    "\n",
    "# ## Select subset of data for review\n",
    "# q = 'SELECT * FROM res_data LIMIT 5'\n",
    "\n",
    "# with db_utils.duckdb_connection(db_path) as conn:\n",
    "#     data = conn.execute(q).df()\n",
    "    \n",
    "# data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backup_data_path = '../data/data_condensed_with_uuid.parquet'\n",
    "\n",
    "data = pd.read_parquet(backup_data_path)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Pre-Engineered Date Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = '../data/engineered_data_dates.parquet'\n",
    "\n",
    "df_dates = pd.read_parquet(filepath)\n",
    "df_dates.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dates.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Condense to Single DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = data.merge(right = df_dates, how = 'left', on = 'UUID')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropping Old Features\n",
    "\n",
    "*Some features were used to engineer new features - particularly arrival details.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_feats = ['LeadTime', 'ArrivalDateYear', 'ArrivalDateMonth', 'ArrivalDateWeekNumber',\n",
    "              'ArrivalDateDayOfMonth', 'StaysInWeekendNights', 'StaysInWeekNights',\n",
    "              'ReservationStatusDate_x', 'ReservationStatusDate_y', 'ArrivalDate',\n",
    "              'DepartureDate', 'BookingDate']\n",
    "drop_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(columns = drop_feats)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abbreviated EDA\n",
    "\n",
    "---\n",
    "\n",
    "- Original notebook reviewed each feature in depth\n",
    "- Abbreviating review for simplicity.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Stats via Describe Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Numeric Stats\n",
    "data.describe(include = 'number')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "- Outliers present in many features\n",
    "- Outlier detection/removal may be required in preprocessing pipeline for certain model types\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Non-Numeric Stats\n",
    "data.describe(exclude = 'number')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "- High cardinality in Country, Agent, Company (disregard UUID; reservation ID)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_sum = data.isna().sum()\n",
    "nan_sum[nan_sum>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_avg = data.isna().mean()\n",
    "nan_avg[nan_avg>0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "- Two features missing values\n",
    "- Average number of missing values less than 1%\n",
    "- No action taken; will address in model pipeline\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_number = data.select_dtypes(include = 'number').columns\n",
    "data_non_num = data.select_dtypes(exclude = 'number').columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data_number].hist(bins = 20, figsize = (18,21), layout = (-1, 5));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-Numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vc_params = {'normalize':True, 'dropna': False, 'ascending': False}\n",
    "\n",
    "for col in data_non_num:\n",
    "    if data[col].nunique() < 10:\n",
    "        print(data[col].value_counts(**vc_params),'\\n')\n",
    "    else:\n",
    "        print(data[col].value_counts(**vc_params)[:5], '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Rare-Label Encoding for categories <5%. Binary encoding for features w/ low variance.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop ReservationStatus, UUID\n",
    "\n",
    "---\n",
    "\n",
    "> `ReservationStatus` is nearly identical to my target feature and would be too strong of a predictor in my models.\n",
    ">\n",
    "> `UUID` is a non-informative unique identifier for each reservation and should be dropped.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[['ReservationStatus', 'IsCanceled']].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-05T17:33:11.076865Z",
     "start_time": "2022-11-05T17:33:10.906251Z"
    }
   },
   "outputs": [],
   "source": [
    "## Dropping \"reservation_status\"\n",
    "data = data.drop(columns = ['ReservationStatus', 'UUID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-05T17:33:11.231443Z",
     "start_time": "2022-11-05T17:33:11.077795Z"
    }
   },
   "outputs": [],
   "source": [
    "## Confirming 'reservation_status' removal from dataframe\n",
    "'ReservationStatus' not in data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  **Post-EDA Updates**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Outliers (continuous features): [OutlierTrimmer using MAD](https://feature-engine.trainindata.com/en/latest/user_guide/outliers/OutlierTrimmer.html#maximum-absolute-deviation)\n",
    "2. Categorical encoding: [DecisionTreeEncoder](https://feature-engine.trainindata.com/en/latest/api_doc/encoding/DecisionTreeEncoder.html#decisiontreeencoder)\n",
    "3. Rare labels (categoricals): [RareLabelEncoding](https://feature-engine.trainindata.com/en/latest/api_doc/encoding/RareLabelEncoder.html#rarelabelencoder)\n",
    "4. Datetime-related features: Review [DatetimeFeatures](https://feature-engine.trainindata.com/en/latest/user_guide/datetime/DatetimeFeatures.html#automating-feature-extraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-05T17:33:12.110167Z",
     "start_time": "2022-11-05T17:33:11.925435Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.head().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Missing Value Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isna().sum()[data.isna().sum() > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from feature_engine.imputation import CategoricalImputer, MeanMedianImputer\n",
    "\n",
    "cat_imputer = CategoricalImputer(variables=['Country'], imputation_method = 'frequent')\n",
    "data_imputed = cat_imputer.fit_transform(data)\n",
    "\n",
    "num_imputer = MeanMedianImputer(imputation_method = 'median', variables = ['Children'])\n",
    "data_imputed = num_imputer.fit_transform(data_imputed)\n",
    "\n",
    "\n",
    "data_imputed.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Categorical Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_imputed.select_dtypes('object').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from feature_engine.encoding import DecisionTreeEncoder, RareLabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rle = RareLabelEncoder(tol=0.05,n_categories=5,replace_with='Rare')\n",
    "\n",
    "data_imputed = rle.fit_transform(data_imputed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dte = DecisionTreeEncoder(regression = True, random_state=42)\n",
    "\n",
    "data_imputed = dte.fit_transform(data_imputed.drop(columns=['ADR']), data_imputed['ADR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_imputed.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from feature_engine.outliers import OutlierTrimmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "olt = OutlierTrimmer(capping_method='gaussian')\n",
    "\n",
    "data_no_outs = olt.fit_transform(data_imputed)\n",
    "data_no_outs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_imputed.shape[0] - data_no_outs.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preserving the Pandas (DataFrame)\n",
    "\n",
    "---\n",
    "\n",
    "Now I am ready to save the cleaned and processed data for modeling in my next notebook.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-05T17:33:17.389381Z",
     "start_time": "2022-11-05T17:33:12.111152Z"
    }
   },
   "outputs": [],
   "source": [
    "# ## Pickling with Pandas\n",
    "# data.to_pickle(path = '../data/data_prepped.pickle',\n",
    "#             compression = 'gzip')\n",
    "# print(f'Successfully pickled!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-05T17:33:17.389381Z",
     "start_time": "2022-11-05T17:33:12.111152Z"
    }
   },
   "outputs": [],
   "source": [
    "## Pickling with Pandas\n",
    "data.to_parquet(path = '../data/data_prepped.parquet')\n",
    "print(f'Successfully saved!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Future Work: EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "In the future, I will revisit the visualization aspects of my EDA function to convert them from Plotly Express figures to Matplotlib figures. The goal with Plotly Express was to have additional interativity; however these models crippled my notebook's operations. Matplotlib figures would be more appropriate in this case, and I will revisit this work when I have more time.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Moving to Modeling!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "> Now that I completed the pre-processing and EDA steps, I will move to my next notebook to perform my classification modeling.\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dojo-env)",
   "language": "python",
   "name": "dojo-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "250.775px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

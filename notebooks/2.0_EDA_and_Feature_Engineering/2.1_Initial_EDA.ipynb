{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Revisiting the Reservations - EDA and Data Wrangling\n",
    "\n",
    "---\n",
    "\n",
    "***Warning: Work-in-Progress***\n",
    "\n",
    "Originally, I used this notebook to perform EDA with the intention of using the dataset only for classifying whether a reservation would cancel.\n",
    "\n",
    "Now, as part of my efforts to revisit and revamp this overall repository and workflow, I am updating and adapting it for broader uses, including regression modeling, classification modeling, and time series forecasting.\n",
    "\n",
    "The end goal is to have a comprehensive overview of the data and to be flexible enough to handle different workflows.\n",
    "\n",
    "\n",
    "As this is a revamp of the original workbook, some of the code and comments may be outdated. I intend to update and clarify all steps in time, but there may be some parts that are out of place while I clean things up.\n",
    "\n",
    "---\n",
    "\n",
    "**Revenue Forecasting**\n",
    "\n",
    "> Proper revenue forecasting is a critical aspect of the revenue management cycle, with the goal to maximize the hotel's revenues. Using the source dataset from two Portuguese hotels (one in an urban location and another a resort), I will utilize machine learning models to forecast the hotels' average daily rate (\"ADR\") based on common reservation details that would be known prior to arrival. \n",
    ">\n",
    "> Before I train any models, I need to get an idea of my data, including its data types; distributions; presence/absence of outliers; and to brainstorm ideas for feature engineering.\n",
    ">\n",
    "> In this notebook, I explore the original dataset and identify specific features to remove from the data. I will determine whether to keep the feature in my modeling based on my domain knowledge of whether this data is commonly known prior to arrival.\n",
    ">\n",
    "> Once the data is prepared, I will perform further modeling and feature engineering in additional notebooks.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-05T17:32:52.290987Z",
     "start_time": "2022-11-05T17:32:52.154639Z"
    }
   },
   "outputs": [],
   "source": [
    "## DEPRECATED - not using custom functions in this noteboook.\n",
    "## Keep this code for future reference/use.\n",
    "\n",
    "## Used to re-import custom functions during development\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "\n",
    "# ## Import necessary modules to enable access to custom functions in separate directory\n",
    "# import os\n",
    "# import sys\n",
    "\n",
    "# # Construct the absolute path to the 'src' directory\n",
    "# src_path = os.path.abspath(os.path.join('../..', 'src'))\n",
    "\n",
    "# # Append the path to 'sys.path'\n",
    "# if src_path not in sys.path:\n",
    "#     sys.path.append(src_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data Handling\n",
    "import duckdb\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "## Visualizations\n",
    "import matplotlib.pyplot as plt\n",
    "import sweetviz as sv\n",
    "\n",
    "## Settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.float_format', lambda x: f'{x:,.2f}')\n",
    "pd.set_option('display.max_rows', 50)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset from Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Create connection to database file\n",
    "\n",
    "# con = create_engine(\"duckdb:///../../data/reservations.duckdb\")\n",
    "# q = '''SELECT *\n",
    "# FROM reservations'''\n",
    "# res_data = pd.read_sql(q, con)\n",
    "\n",
    "# q = '''SELECT *\n",
    "# FROM guests'''\n",
    "# guests_data = pd.read_sql(q, con)\n",
    "\n",
    "# q = '''SELECT *\n",
    "# FROM rooms'''\n",
    "# rooms_data = pd.read_sql(q, con)\n",
    "\n",
    "# q = '''SELECT *\n",
    "# FROM bookingagents'''\n",
    "# ba_data = pd.read_sql(q, con)\n",
    "\n",
    "# q = '''SELECT *\n",
    "# FROM BookingDetails'''\n",
    "# bd_data = pd.read_sql(q, con)\n",
    "\n",
    "# data = pd.merge(left = res_data, right = rooms_data, on = 'UUID', how = 'outer')\n",
    "# data = pd.merge(left = data, right = guests_data, on = 'UUID', how = 'outer')\n",
    "# data = pd.merge(left = data, right = ba_data, on = 'UUID', how = 'outer')\n",
    "# data = pd.merge(left = data, right = bd_data, on = 'UUID', how = 'outer')\n",
    "# data = data.set_index('UUID')\n",
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../../data/source/full_data.feather'\n",
    "\n",
    "data = pd.read_feather(path)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sweetviz Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = sv.analyze(data,pairwise_analysis = 'off')\n",
    "\n",
    "report.show_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "***Feature Reviews***\n",
    "\n",
    "IsCanceled - Binary, but needs to be validated (i.e., what indicates the reservation was canceled? How was this feature created?)\n",
    "\n",
    "LeadTime - Right-skewed; may benefit from a Yeo-Johnson transformation or just drop the outliers.\n",
    "\n",
    "All date features - move to feature engineering for time series details.\n",
    "\n",
    "Adults, Children, Babies - Right-skewed; transform or drop.\n",
    "\n",
    "Meal - Categorical, perform encoding during modeling pipeline preprocessing\n",
    "\n",
    "Country - Categorical, perform encoding during modeling pipeline preprocessing\n",
    "\n",
    "PreviousCancellations/PreviousBookingsNotCancelled - useful for forecasting after reservations booked; harder to use for pre-booking revenue forecasting.\n",
    "\n",
    "BookedRoomType/AssignedRoomType - `AssignedRoomType` not known until after stay; possible candidate for classification modeling for feature engineering (e.g., which room type assigned; whether booking matches assignment).\n",
    "\n",
    "BookingChanges - Right-skewed, transform during preprocessing\n",
    "\n",
    "DepositType - Categorical, perform encoding during modeling pipeline preprocessing\n",
    "\n",
    "Agent, Company - Categorical, perform encoding during modeling pipeline preprocessing\n",
    "\n",
    "DaysInWaitingList - Right-skewed, transform during preprocessing\n",
    "\n",
    "ADR - target feature; negative values (decide whether to keep, drop, or add absolute value of largest negative value to all ADRs to bring to zero); right-skewed, would benefit from a TransformedTargetRegressor w/ PowerTransformer.\n",
    "\n",
    "RequiredParkingSpaces - Right-skewed, transform during preprocessing\n",
    "\n",
    "ReservationStatus - used to determine `IsCanceled`; possibly use with other features to engineer new target feature that includes ADR, etc.\n",
    "\n",
    "ReservationStatusDate - use in temporal feature engineering\n",
    "\n",
    "---\n",
    "\n",
    "**Review Results**\n",
    "\n",
    "Based on the report, each hotel exibits several numeric features with outliers, as well as several features with high cardinality. There are also several features showing a high degree of multicollinearity.\n",
    "\n",
    "---\n",
    "\n",
    "**Processing Steps**\n",
    "\n",
    "* *Outliers and Skew:* Many of the numeric features are right-skewed with some extreme outliers. My initial thoughts are to preserve the details and perform a Yeo-Johnson transformation using a `PowerTransformer` during the modeling preprocessing. However, I may choose to drop these records as they are such extreme values.\n",
    "\n",
    "* *Categoricals and High Cardinality* - I need to encode each feature, but I want to avoid one-hot encoding due to the high cardinality of the features. Instead, I will use a CountFrequencyEncoder to convert the categories into the frequency of each class.\n",
    "\n",
    "* *Multicollinearity* - Only concering for linear models. Use methods such as VIF to remove features with high multicollinearity.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Stats via Describe Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Numeric Stats\n",
    "data.describe(include = 'number').T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "- Outliers present in nearly half of the features\n",
    "- Power transformations/removal may be required in preprocessing pipeline to minimize impact on models\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Non-Numeric Stats\n",
    "data.describe(exclude = 'number').T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "- High cardinality in Country, Agent, Company\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_sum = data.isna().sum()\n",
    "nan_sum[nan_sum > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_avg = data.isna().mean()\n",
    "nan_avg[nan_avg > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "- Two features missing values\n",
    "- Average number of missing values less than 1%\n",
    "- No action taken; will address in model pipeline\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection - Known at Booking/Pre-Arrival\n",
    "\n",
    "---\n",
    "\n",
    "Based on my domain knowledge and experience, I know there are a few features that would not be known prior to booking/pre-arrival. These features should be excluded from the analysis and modeling, but I could create additional models to predict the values for each of these features.\n",
    "\n",
    "**Reservation-Specific Features**\n",
    "\n",
    "* Meal\n",
    "* IsRepeatedGuest\n",
    "* PreviousCancellations\n",
    "* PreviousBookingsNotCanceled\n",
    "\n",
    "**Post-Stay Details**\n",
    "\n",
    "* AssignedRoomType\n",
    "* BookingChanges\n",
    "* DepositType\n",
    "* DaysInWaitingList\n",
    "* RequiredCarParkingSpaces\n",
    "* ReservationStatus\n",
    "* ReservationStatusDate\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create JSON File to Record Column Groups\n",
    "\n",
    "---\n",
    "\n",
    "Since I know I will need to use subsets of different features for different analyses and models, I will preemptively define different groups of features to use as filters in the rest of my workflow.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define custon groups of features\n",
    "column_groups = {\n",
    "    'booking_details': ['UUID', 'HotelNumber', 'LeadTime', 'ArrivalDateMonth',\n",
    "                        'ArrivalDateWeekNumber','ArrivalDateDayOfMonth',\n",
    "                        'StaysInWeekendNights','StaysInWeekNights','Adults',\n",
    "                        'Children', 'Babies','Country','MarketSegment',\n",
    "                        'DistributionChannel','ReservedRoomType',\n",
    "                        'DepositType','Agent','Company','CustomerType','ADR'],\n",
    "    'post_stay_details': ['UUID', 'AssignedRoomType','BookingChanges',\n",
    "                          'DaysInWaitingList','RequiredCarParkingSpaces',\n",
    "                          'ReservationStatus','ReservationStatusDate'],\n",
    "    'reservation_specific': ['UUID', 'Meal', 'IsRepeatedGuest','PreviousCancellations',\n",
    "                             'PreviousBookingsNotCanceled'],\n",
    "    'temporal_features': ['UUID', 'LeadTime', 'ArrivalDateYear', 'ArrivalDateMonth',\n",
    "                          'ArrivalDateWeekNumber','ArrivalDateDayOfMonth',\n",
    "                          'StaysInWeekendNights','StaysInWeekNights',\n",
    "                          'ReservationStatusDate']\n",
    "}\n",
    "\n",
    "## Save results to JSON file\n",
    "file_name = '../../data/column_groups.json'\n",
    "with open(file_name, 'w') as json_file:\n",
    "    json.dump(column_groups, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[column_groups['booking_details']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial EDA - Review\n",
    "\n",
    "---\n",
    "\n",
    "**Disfunctional Features**\n",
    "\n",
    "> This inital EDA highlighted several problems with the overall dataset, including:\n",
    "> * Extreme outliers for several numeric features;\n",
    "> * High cardinality for several categorical features;\n",
    "> * Temporal features that need to be re-engineered;\n",
    "> * Questions about how the `IsCanceled` feature was created.\n",
    "\n",
    "**Next Steps**\n",
    "\n",
    "> The next steps will include:\n",
    "> * Transforming outliers in numeric features via PowerTransformer;\n",
    "> * Rare-label encoding for categorical features with high cardinality;\n",
    "> * Re-engineering the temporal features for regression and classification modeling;\n",
    "> * Either dropping or re-engineering the `IsCanceled` feature due to the ambiguity of its engineering.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ds-env)",
   "language": "python",
   "name": "ds-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "250.775px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "086b5f8fdb8443f385b1a4e4c17f18f9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "09a6e4db3f784cd6ba6aff64a068b6e0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_ee701e0f687049a9bd0e8e495d9189b3",
       "style": "IPY_MODEL_dfb201302d734a93bf2071b0a8f14525",
       "value": "Feature: UUID                                "
      }
     },
     "12a61cbee970417db8b54f99c3151b94": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_93abff4e6e2544dc8bb9c2581bca922d",
       "max": 33,
       "style": "IPY_MODEL_eac3ac2377be485cab0d3eb12aad157f",
       "value": 33
      }
     },
     "412b00f928354bb39cfb0d20c9d4df74": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_09a6e4db3f784cd6ba6aff64a068b6e0",
        "IPY_MODEL_12a61cbee970417db8b54f99c3151b94",
        "IPY_MODEL_59f272642ffe49fa973a162175080e70"
       ],
       "layout": "IPY_MODEL_4965f5550a604173bc2c08942a386e6f"
      }
     },
     "4965f5550a604173bc2c08942a386e6f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "display": "inline-flex",
       "flex_flow": "row wrap",
       "width": "100%"
      }
     },
     "59f272642ffe49fa973a162175080e70": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_086b5f8fdb8443f385b1a4e4c17f18f9",
       "style": "IPY_MODEL_db12f37bf1864255b1f65f8c445d5686",
       "value": " [100%]   00:06 -&gt; (00:00 left)"
      }
     },
     "93abff4e6e2544dc8bb9c2581bca922d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "flex": "2"
      }
     },
     "db12f37bf1864255b1f65f8c445d5686": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "dfb201302d734a93bf2071b0a8f14525": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "eac3ac2377be485cab0d3eb12aad157f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "ee701e0f687049a9bd0e8e495d9189b3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
